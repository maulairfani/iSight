{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "# Load & process\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Vector store & embeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Conversations\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Post-processing\n",
    "import fitz\n",
    "\n",
    "# Token counter\n",
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "from langchain.callbacks.manager import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader('pdfs/2309.13963.pdf')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into chunks\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings from chunks\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "# Template prompt\n",
    "template = \"\"\"Based ONLY on the context below, answer the following question!\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contexts_formatter(contexts):\n",
    "    result = \"\"\n",
    "    for i in range(len(contexts)):\n",
    "        result += f\"{i+1}. {contexts[i].page_content}\\n\\n\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berdasarkan konteks di atas, Q-Former adalah sebuah modul yang berbasis Transformer yang digunakan untuk mengubah urutan masukan yang berkepanjangan menjadi representasi kueri (query) dengan panjang tetap. Modul ini awalnya dikembangkan untuk pencocokan modalitas visual-teks, tetapi dalam konteks ini, Q-Former digunakan untuk mencocokkan audio-teks. Dalam blok Q-Former, embedding kueri yang dapat dilatih (trainable query embeddings) berinteraksi dengan fitur masukan melalui lapisan self-attention dan cross-attention multi-head. Q-Former ini terdiri dari dua blok decoder Transformer dengan masker perhatian kausal dihilangkan."
     ]
    }
   ],
   "source": [
    "question = \"jelasin apa itu q-former\"\n",
    "contexts = docsearch.similarity_search(question, k=3)\n",
    "\n",
    "answer = \"\"\n",
    "for res in chain.stream({\"context\": contexts_formatter(contexts), \"question\": question, \"chat_history\": memory.buffer_as_messages}):\n",
    "    if res:\n",
    "        print(res.content, end=\"\", flush=True)\n",
    "        answer += res.content\n",
    "\n",
    "# with get_openai_callback() as cb:\n",
    "#     res_invoke = chain.invoke({\"context\": contexts_formatter(contexts), \"question\": question, \"chat_history\": memory.buffer_as_messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berdasarkan konteks di atas, Q-Former adalah sebuah modul yang berbasis Transformer yang digunakan untuk mengubah urutan masukan yang berkepanjangan menjadi representasi kueri (query) dengan panjang tetap. Modul ini awalnya dikembangkan untuk pencocokan modalitas visual-teks, tetapi dalam konteks ini, Q-Former digunakan untuk mencocokkan audio-teks. Dalam blok Q-Former, embedding kueri yang dapat dilatih (trainable query embeddings) berinteraksi dengan fitur masukan melalui lapisan self-attention dan cross-attention multi-head. Q-Former ini terdiri dari dua blok decoder Transformer dengan masker perhatian kausal dihilangkan.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template prompt\n",
    "template_reference = \"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Based on the question and answer pair above, find where the answer originates from within the given context.\n",
    "\n",
    "Return a JSON object with the following keys:\n",
    "    `page`: (the value is in the form of a list of page numbers, can be more than one page)\n",
    "    `source`: (the value is in the form of a list of sentences used as a reference for the answer, write exactly as it appears in the context including the in-text citation, using the language used in the context)\n",
    "    `in-text citation` : (list of in-text citation appears in contexts used as reference for the answer)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_reference = PromptTemplate.from_template(template_reference)\n",
    "\n",
    "# LLm\n",
    "llm = OpenAI()\n",
    "\n",
    "# Output parser\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "# LCEL\n",
    "reference_chain = prompt_reference | llm | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = reference_chain.invoke({\n",
    "    \"context\": contexts_formatter(contexts), \n",
    "    \"question\": question, \n",
    "    \"answer\": answer\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Q-Former [20] is a Transformer-based module converting variable-',\n",
       "  'length input sequences into fixed-length output query representa',\n",
       "  'tions. It was initially proposed for visual-text modality alignment,',\n",
       "  'and here is applied to audio-text alignment. In each Q-Former block,',\n",
       "  'trainable query embeddings Q∈Rnq×dqinteract with the input fea',\n",
       "  'turesXthrough multi-head self-attention and cross-attention layers,'],\n",
       " [1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "\n",
    "matches = list()\n",
    "pages = list()\n",
    "for i in range(3):\n",
    "    m = [m for m in SequenceMatcher(None, contexts[i].page_content, reference[\"source\"][0]).get_matching_blocks() if m.size > 15]\n",
    "    if m:\n",
    "        # m = contexts[i].page_content[m[0].a : m[-1].a + m[-1].size]\n",
    "        # matches.append(m)\n",
    "        for j in range(len(m)):\n",
    "            matches.append(contexts[i].page_content[m[j].a : m[j].a + m[j].size])\n",
    "            pages.append(contexts[i].metadata[\"page\"])\n",
    "\n",
    "pd.DataFrame({\"match\": matches, \"pages\": pages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dict_to_string(input_dict):\n",
    "    json_string = json.dumps(input_dict, indent=2)  # indent for pretty formatting (optional)\n",
    "    return json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forex_python.converter import CurrencyRates\n",
    "\n",
    "def get_cost(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        prompt_formatted=prompt.format(context=contexts_formatter(contexts), question=question, chat_history=memory.buffer_as_messages),\n",
    "        output_from_llm=dict_to_string(res)\n",
    "):\n",
    "    curr = CurrencyRates()\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    input_tokens_used = len(encoder.encode(prompt_formatted)) + 7 # Jaga-jaga\n",
    "    output_tokens_used = len(encoder.encode(output_from_llm))\n",
    "    total_token = input_tokens_used + output_tokens_used\n",
    "\n",
    "    input_price = round((0.0015/1000) * input_tokens_used, 8)\n",
    "    output_price = round((0.002/1000) * output_tokens_used, 8)\n",
    "    total_price_usd = round(input_price + output_price, 8)\n",
    "    total_price_idr = curr.convert('USD', 'IDR', total_price_usd)\n",
    "\n",
    "\n",
    "    return f\"\"\"Tokens Used: {total_token}\n",
    "        Prompt Tokens: {input_tokens_used}\n",
    "        Completion Tokens: {output_tokens_used}\n",
    "    Total Cost (USD): ${total_price_usd}\n",
    "    Total Cost (IDR): Rp{total_price_idr}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting Sources\n",
    "def get_matches(source, contexts=contexts, k=3):\n",
    "    for i in range(k):\n",
    "        idx_awal = contexts[i].page_content.find(source)\n",
    "        if idx_awal != -1:\n",
    "            idx_akhir = contexts[i].page_content[idx_awal:].find(\".\")\n",
    "            idx_akhir += idx_awal\n",
    "        \n",
    "            match_ = contexts[i].page_content[idx_awal:idx_akhir]\n",
    "            if len(match_) > 10:\n",
    "                page_num = contexts[i].metadata[\"page\"]\n",
    "                return contexts[i].page_content[idx_awal:idx_akhir], page_num\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def highlight_pdf(path, match_, page_num, output_path):\n",
    "    pdf = fitz.open(path)\n",
    "    page = pdf[page_num]\n",
    "\n",
    "    matches = page.search_for(match_.replace(\"-\\n\", \"\"))\n",
    "\n",
    "    for m in matches:\n",
    "        page.add_highlight_annot(m)\n",
    "\n",
    "    pdf.save(output_path)\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get references\n",
    "def get_reference(docs, in_text_citation):\n",
    "    model = OpenAI()\n",
    "\n",
    "    get_citation_template = \"\"\"From the reference list below, rewrite the specified references!\n",
    "    References:\n",
    "    {references}\n",
    "\n",
    "    Please rewrite the references related to the following numbers:\n",
    "    {in_text_citation}\n",
    "    \"\"\"\n",
    "\n",
    "    GET_CITATION_PROMPT = PromptTemplate.from_template(get_citation_template)\n",
    "\n",
    "    get_reference_chain = chain = GET_CITATION_PROMPT | model\n",
    "\n",
    "    for page_number in range(len(docs)):\n",
    "        page = docs[page_number]\n",
    "        text = page.page_content\n",
    "\n",
    "        if \"References\" in text or \"REFERENCES\" in text:\n",
    "            references_text = text.split(\"References\")[1] if \"References\" in text else text.split(\"REFERENCES\")[1]\n",
    "\n",
    "    result = get_reference_chain.invoke({\"references\": references_text, \"in_text_citation\":in_text_citation})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if res[\"source\"]:\n",
    "    match_, page_num = get_matches(res[\"source\"][:15], contexts)\n",
    "\n",
    "    if match_:\n",
    "        highlight_pdf(\"pdfs/2309.13963.pdf\", match_, page_num, \"pdfs/highlighted/high_pdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_pdf(\"pdfs/2309.13963.pdf\", matches[3], 1, \"pdfs/highlighted/high_pdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20] J. Li, D. Li, S. Savarese, and S. Hoi, “BLIP-2: Bootstrapping Language-Image Pre-Training with Frozen Image Encoders and Large Language Models,” in Proc. ICML , Vienna, 2023.\n"
     ]
    }
   ],
   "source": [
    "if reference[\"in-text citation\"]:\n",
    "    ref_result = get_reference(docs, reference[\"in-text citation\"]).strip()\n",
    "print(ref_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
